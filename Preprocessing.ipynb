{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import glob as gb\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,trange\n",
    "from time import sleep\n",
    "from torchsummary import summary\n",
    "# from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tueday 21:14 13/10/2020\n",
    "\n",
    "@author: Keira - github.com/Keira. Bai\n",
    "\n",
    "For pre-process on frame level \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoaData(datapaths, vid_dir,imgpath):\n",
    "    dataset = []\n",
    "    expset = []\n",
    "    exp = [0,0,0,0]\n",
    "    \n",
    "    for i in range(len(vid_dir)):\n",
    "        DataStream = gb.glob(datapaths+vid_dir[i]+imgpath)\n",
    "\n",
    "        dataset += DataStream\n",
    "        exp[i] += len(DataStream)\n",
    "        expset.extend(i for j in range(len(DataStream)))\n",
    "    return dataset, expset,exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(tran_r,tran_t,img):\n",
    "    img3 = tran_r(img)\n",
    "    img3 = tran_t(img3)\n",
    "    return img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation(dataset, expset, tran_r,tran_t):\n",
    "    imgset = []#image tensor\n",
    "    label = []#exp after augmentation\n",
    "    expA = [0,0,0,0] \n",
    "    \n",
    "    for img_name,exp in zip(dataset, expset):\n",
    "        #orginal images\n",
    "        img = mpimg.imread(img_name)  \n",
    "        img = Image.fromarray(img) \n",
    "        img1 = tran_t(img) \n",
    "        imgset.append(img1)\n",
    "        label.append(exp)\n",
    "        expA[exp] += 1\n",
    "\n",
    "        #flip for non-micro 2times\n",
    "        imgf = transforms.functional.hflip(img)\n",
    "        img2 = tran_t(imgf)\n",
    "        imgset.append(img2)\n",
    "        label.append(exp)\n",
    "        expA[exp] += 1\n",
    "\n",
    "        #if the expression is not non-micro-expression\n",
    "        if exp < 3:\n",
    "            for i in range(3):# for negative 5times\n",
    "                imgset.append(rotation(tran_r,tran_t,img))\n",
    "                label.append(exp)  \n",
    "                expA[exp] += 1\n",
    "            if exp == 1:#for positive 6times\n",
    "                imgset.append(rotation(tran_r,tran_t,img))\n",
    "                label.append(exp) \n",
    "                expA[exp] += 1\n",
    "            if exp == 2:#for surprise 8times\n",
    "                for i in range(2):\n",
    "                    imgset.append(rotation(tran_r,tran_t,img))\n",
    "                    label.append(exp)  \n",
    "                    expA[exp] += 1\n",
    "    return imgset, label, expA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload(imgset, label):\n",
    "    samp_set = []\n",
    "    for i,l in zip(imgset, label):\n",
    "        sample = [i,l]\n",
    "        samp_set.append(sample)\n",
    "    return samp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataloder():\n",
    "    datapaths = \"../SMIC/SMIC_all_cropped/HS/*/\"\n",
    "    vid_dir = [\"*/negative/*\", \"*/positive/*\", \"*/surprise/*\",\"non_micro/*\"]\n",
    "    imgpath = \"/*.bmp\"\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()  \n",
    "    tran_t = transforms.Compose(\n",
    "        [transforms.Resize([224,224]), \n",
    "         transforms.ToTensor(),     \n",
    "        ])\n",
    "    tran_r = transforms.Compose(\n",
    "        [transforms.RandomRotation(10),        \n",
    "        ])\n",
    "    params = {'batch_size': 8, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    dataset, expset, exp = LoaData(datapaths, vid_dir,imgpath) \n",
    "    imgset, label, expA = Augmentation(dataset, expset, tran_r,tran_t)\n",
    "    print(\"Total samples number:\", len(label))\n",
    "    print(\"Number of 4 categories:\", exp)\n",
    "    print(\"Number of 4 categories after augmentation\", expA)\n",
    "\n",
    "    train_label, test_label = train_test_split(label,test_size=1/4, random_state=42)\n",
    "    train_set = reload(imgset[:len(train_label)], label[:len(train_label)])\n",
    "    test_set = reload(imgset[len(train_label):], label[len(train_label):])\n",
    "    train_loader = data.DataLoader(train_set, **params)\n",
    "    test_loader = data.DataLoader(test_set, **params)\n",
    "\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
