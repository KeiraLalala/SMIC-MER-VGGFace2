{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import glob as gb\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# import resnet50_128_redesign as model\n",
    "import resnet50_128B8 as model\n",
    "from PIL import Image\n",
    "from tqdm import tqdm,trange\n",
    "from torchsummary import summary\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_, clip_grad_value_\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from DataProcessing import process_dataloder\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 6/10448 [00:00<03:13, 54.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "folders for train and test:  245 83\n",
      "----------\n",
      "data for train and test:\n",
      "['negative', 'positive', 'surprise', 'non_micro-expression']\n",
      "train [2168, 1856, 1408, 5016]\n",
      "test [832, 600, 576, 1816]\n",
      "dataset_size: {'train': [0, 10448], 'test': [10448, 14272]}\n",
      "---------- load data ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 10448/10448 [01:05<00:00, 158.69it/s]\n",
      "test:   0%|          | 12/3824 [00:00<00:32, 118.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- load data ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 3824/3824 [00:25<00:00, 150.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete in 1m 31s\n",
      "After augmentation\n",
      "{'train': 43272, 'test': 16000}\n",
      "['negative', 'positive', 'surprise', 'non_micro-expression']\n",
      "{'train': [10840, 11136, 11264, 10032], 'test': [4160, 3600, 4608, 3632]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloaders, class_names, dataset_sizes, expA = process_dataloder()\n",
    "print(\"After augmentation\")\n",
    "print(dataset_sizes)\n",
    "print(class_names)\n",
    "print(expA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclical_lr(stepsize, min_lr, max_lr):\n",
    "\n",
    "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
    "    scaler = lambda x: 1.\n",
    "\n",
    "    # Lambda function to calculate the LR\n",
    "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
    "\n",
    "    # Additional function to see where on the cycle we are\n",
    "    def relative(it, stepsize):\n",
    "        cycle = math.floor(1 + it / (2 * stepsize))\n",
    "        x = abs(it / stepsize - 2 * cycle + 1)\n",
    "        return max(0, (1 - x)) * scaler(cycle)\n",
    "\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(phase, model, criterion, optimizer):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    nb_classes = 4\n",
    "    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "\n",
    "    # Iterate over data.        \n",
    "    for inputs, labels in dataloaders[phase]:            \n",
    "        inputs = inputs.to(device)            \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            \n",
    "            outputs = model(inputs)            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)    \n",
    "            \n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                clip_grad_norm_(model.parameters(), 5)\n",
    "                optimizer.step()  \n",
    "            if phase == 'test':              \n",
    "                with torch.no_grad():\n",
    "                    for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data) \n",
    "        \n",
    "    if phase == 'test':\n",
    "        print(confusion_matrix)\n",
    "\n",
    "    return running_loss, running_corrects     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_mode(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    logs = []\n",
    "    Acc = {'train':[],'test':[]}\n",
    "    Los = {'train':[],'test':[]}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss, running_corrects = training(phase, model, criterion, optimizer)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                lr_sched_test = scheduler.get_lr()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())      \n",
    "            Acc[phase].append(epoch_acc)\n",
    "            Los[phase].append(epoch_loss)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, Acc, Los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the pre-trained model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# modelRes50 = model.resnet50_128(weights_path='./model/resnet50_128.pth')\n",
    "# modelRes50.add_module(\"feat_extract1\",nn.Conv2d(128, 64, kernel_size=[1, 1], stride=(1, 1), bias=False))\n",
    "# modelRes50.add_module(\"feat_extract2\",nn.Conv2d(64, 4, kernel_size=[1, 1], stride=(1, 1), bias=False))\n",
    "# modelRes50.add_layers([modelRes50.feat_extract1, modelRes50.feat_extract2])\n",
    "# modelRes50 = modelRes50.to(device)\n",
    "# features_layers = 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers before classifier\n",
    "def freezing(model, features_layers):\n",
    "    lay_mark = 0;\n",
    "    para_list = []\n",
    "    for param in modelRes50.parameters():\n",
    "        if lay_mark > features_layers:\n",
    "            para_list.append(param)\n",
    "        if lay_mark <= features_layers:\n",
    "            param.requires_grad = False\n",
    "        lay_mark += 1\n",
    "    return model, para_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final layer are being optimized \n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer_ft = optim.SGD(para_list, lr=0.00035, momentum=0.9)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/74\n",
      "----------\n",
      "train Loss: 0.6378 Acc: 0.9185\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3600.,    0.,    0.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3632.,    0.,    0.]])\n",
      "test Loss: 5.5066 Acc: 0.2250\n",
      "Epoch 1/74\n",
      "----------\n",
      "train Loss: 0.5793 Acc: 0.9186\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3600.,    0.,    0.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3632.,    0.,    0.]])\n",
      "test Loss: 5.1549 Acc: 0.2250\n",
      "Epoch 2/74\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 0.9096\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3600.,    0.,    0.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3632.,    0.,    0.]])\n",
      "test Loss: 10.4189 Acc: 0.2250\n",
      "Epoch 3/74\n",
      "----------\n",
      "train Loss: 0.6462 Acc: 0.9030\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3600.,    0.,    0.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3632.,    0.,    0.]])\n",
      "test Loss: 8.9901 Acc: 0.2250\n",
      "Epoch 4/74\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.8963\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3600.,    0.,    0.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3632.,    0.,    0.]])\n",
      "test Loss: 7.0689 Acc: 0.2250\n",
      "Epoch 5/74\n",
      "----------\n",
      "train Loss: 0.5989 Acc: 0.8966\n",
      "tensor([[   0., 4160.,    0.,    0.],\n",
      "        [   0., 3592.,    0.,    8.],\n",
      "        [   0., 4608.,    0.,    0.],\n",
      "        [   0., 3611.,    0.,   21.]])\n",
      "test Loss: 6.2809 Acc: 0.2258\n",
      "Epoch 6/74\n",
      "----------\n",
      "train Loss: 0.5612 Acc: 0.8939\n",
      "tensor([[1.3000e+01, 4.1000e+03, 0.0000e+00, 4.7000e+01],\n",
      "        [3.0000e+00, 3.4460e+03, 0.0000e+00, 1.5100e+02],\n",
      "        [0.0000e+00, 4.6080e+03, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 3.4830e+03, 0.0000e+00, 1.3700e+02]])\n",
      "test Loss: 5.6375 Acc: 0.2248\n",
      "Epoch 7/74\n",
      "----------\n",
      "train Loss: 0.5288 Acc: 0.8939\n",
      "tensor([[ 208., 3756.,    0.,  196.],\n",
      "        [ 142., 3238.,    0.,  220.],\n",
      "        [  26., 4540.,    0.,   42.],\n",
      "        [ 111., 3120.,    0.,  401.]])\n",
      "test Loss: 5.1668 Acc: 0.2404\n",
      "Epoch 8/74\n",
      "----------\n",
      "train Loss: 0.5022 Acc: 0.8937\n",
      "tensor([[4.5700e+02, 3.4440e+03, 2.0000e+00, 2.5700e+02],\n",
      "        [4.0700e+02, 2.9760e+03, 1.2000e+01, 2.0500e+02],\n",
      "        [1.4400e+02, 4.3860e+03, 0.0000e+00, 7.8000e+01],\n",
      "        [2.7500e+02, 2.8560e+03, 0.0000e+00, 5.0100e+02]])\n",
      "test Loss: 4.8162 Acc: 0.2459\n",
      "Epoch 9/74\n",
      "----------\n",
      "train Loss: 0.4737 Acc: 0.8933\n",
      "tensor([[ 597., 3266.,   12.,  285.],\n",
      "        [ 538., 2824.,   45.,  193.],\n",
      "        [ 258., 4276.,    0.,   74.],\n",
      "        [ 432., 2679.,    0.,  521.]])\n",
      "test Loss: 4.5629 Acc: 0.2464\n",
      "Epoch 10/74\n",
      "----------\n",
      "train Loss: 0.4469 Acc: 0.8944\n",
      "tensor([[6.6100e+02, 3.1920e+03, 2.4000e+01, 2.8300e+02],\n",
      "        [5.8800e+02, 2.7810e+03, 4.8000e+01, 1.8300e+02],\n",
      "        [3.1900e+02, 4.1990e+03, 2.2000e+01, 6.8000e+01],\n",
      "        [5.2200e+02, 2.6030e+03, 1.0000e+00, 5.0600e+02]])\n",
      "test Loss: 4.3844 Acc: 0.2481\n",
      "Epoch 11/74\n",
      "----------\n",
      "train Loss: 0.4246 Acc: 0.8952\n",
      "tensor([[ 651., 3186.,   49.,  274.],\n",
      "        [ 583., 2792.,   37.,  188.],\n",
      "        [ 265., 4137.,  117.,   89.],\n",
      "        [ 517., 2559.,   64.,  492.]])\n",
      "test Loss: 4.2428 Acc: 0.2533\n",
      "Epoch 12/74\n",
      "----------\n",
      "train Loss: 0.4048 Acc: 0.8957\n",
      "tensor([[ 569., 3185.,  125.,  281.],\n",
      "        [ 518., 2823.,   27.,  232.],\n",
      "        [ 153., 4063.,  281.,  111.],\n",
      "        [ 422., 2511.,  148.,  551.]])\n",
      "test Loss: 4.1231 Acc: 0.2640\n",
      "Epoch 13/74\n",
      "----------\n",
      "train Loss: 0.3871 Acc: 0.8968\n",
      "tensor([[ 450., 3161.,  216.,  333.],\n",
      "        [ 451., 2845.,   44.,  260.],\n",
      "        [  79., 4011.,  393.,  125.],\n",
      "        [ 333., 2465.,  188.,  646.]])\n",
      "test Loss: 4.0162 Acc: 0.2709\n",
      "Epoch 14/74\n",
      "----------\n",
      "train Loss: 0.3710 Acc: 0.8984\n",
      "tensor([[ 359., 3135.,  266.,  400.],\n",
      "        [ 362., 2844.,   95.,  299.],\n",
      "        [  62., 3982.,  428.,  136.],\n",
      "        [ 221., 2406.,  190.,  815.]])\n",
      "test Loss: 3.9174 Acc: 0.2779\n",
      "Epoch 15/74\n",
      "----------\n",
      "train Loss: 0.3573 Acc: 0.9005\n",
      "tensor([[ 311., 3079.,  291.,  479.],\n",
      "        [ 296., 2833.,  114.,  357.],\n",
      "        [  65., 3955.,  430.,  158.],\n",
      "        [ 182., 2305.,  150.,  995.]])\n",
      "test Loss: 3.8191 Acc: 0.2856\n",
      "Epoch 16/74\n",
      "----------\n",
      "train Loss: 0.3449 Acc: 0.9014\n",
      "tensor([[ 288., 2982.,  324.,  566.],\n",
      "        [ 259., 2811.,  142.,  388.],\n",
      "        [  74., 3935.,  418.,  181.],\n",
      "        [ 140., 2196.,  101., 1195.]])\n",
      "test Loss: 3.7201 Acc: 0.2945\n",
      "Epoch 17/74\n",
      "----------\n",
      "train Loss: 0.3342 Acc: 0.9028\n",
      "tensor([[ 275., 2860.,  355.,  670.],\n",
      "        [ 227., 2785.,  166.,  422.],\n",
      "        [  90., 3923.,  403.,  192.],\n",
      "        [ 121., 2122.,   69., 1320.]])\n",
      "test Loss: 3.6244 Acc: 0.2989\n",
      "Epoch 18/74\n",
      "----------\n",
      "train Loss: 0.3248 Acc: 0.9047\n",
      "tensor([[ 270., 2742.,  396.,  752.],\n",
      "        [ 208., 2747.,  182.,  463.],\n",
      "        [ 107., 3908.,  393.,  200.],\n",
      "        [ 113., 2050.,   59., 1410.]])\n",
      "test Loss: 3.5346 Acc: 0.3013\n",
      "Epoch 19/74\n",
      "----------\n",
      "train Loss: 0.3165 Acc: 0.9068\n",
      "tensor([[ 258., 2621.,  448.,  833.],\n",
      "        [ 193., 2706.,  198.,  503.],\n",
      "        [ 134., 3893.,  375.,  206.],\n",
      "        [ 105., 1957.,   59., 1511.]])\n",
      "test Loss: 3.4526 Acc: 0.3031\n",
      "Epoch 20/74\n",
      "----------\n",
      "train Loss: 0.3091 Acc: 0.9090\n",
      "tensor([[ 256., 2526.,  479.,  899.],\n",
      "        [ 190., 2671.,  214.,  525.],\n",
      "        [ 148., 3882.,  368.,  210.],\n",
      "        [  97., 1885.,   59., 1591.]])\n",
      "test Loss: 3.3786 Acc: 0.3054\n",
      "Epoch 21/74\n",
      "----------\n",
      "train Loss: 0.3023 Acc: 0.9112\n",
      "tensor([[ 245., 2393.,  530.,  992.],\n",
      "        [ 186., 2629.,  232.,  553.],\n",
      "        [ 161., 3868.,  359.,  220.],\n",
      "        [  88., 1864.,   71., 1609.]])\n",
      "test Loss: 3.3116 Acc: 0.3026\n",
      "Epoch 22/74\n",
      "----------\n",
      "train Loss: 0.2959 Acc: 0.9134\n",
      "tensor([[ 229., 2254.,  582., 1095.],\n",
      "        [ 174., 2589.,  264.,  573.],\n",
      "        [ 168., 3860.,  355.,  225.],\n",
      "        [  80., 1839.,   82., 1631.]])\n",
      "test Loss: 3.2514 Acc: 0.3003\n",
      "Epoch 23/74\n",
      "----------\n",
      "train Loss: 0.2898 Acc: 0.9153\n",
      "tensor([[ 213., 2144.,  639., 1164.],\n",
      "        [ 154., 2541.,  300.,  605.],\n",
      "        [ 177., 3846.,  351.,  234.],\n",
      "        [  69., 1823.,   90., 1650.]])\n",
      "test Loss: 3.1972 Acc: 0.2972\n",
      "Epoch 24/74\n",
      "----------\n",
      "train Loss: 0.2843 Acc: 0.9167\n",
      "tensor([[ 194., 2064.,  688., 1214.],\n",
      "        [ 143., 2502.,  331.,  624.],\n",
      "        [ 175., 3830.,  357.,  246.],\n",
      "        [  60., 1806.,  100., 1666.]])\n",
      "test Loss: 3.1477 Acc: 0.2949\n",
      "Epoch 25/74\n",
      "----------\n",
      "train Loss: 0.2790 Acc: 0.9178\n",
      "tensor([[ 177., 2015.,  723., 1245.],\n",
      "        [ 133., 2475.,  363.,  629.],\n",
      "        [ 174., 3817.,  360.,  257.],\n",
      "        [  59., 1793.,  100., 1680.]])\n",
      "test Loss: 3.1020 Acc: 0.2933\n",
      "Epoch 26/74\n",
      "----------\n",
      "train Loss: 0.2741 Acc: 0.9193\n",
      "tensor([[ 170., 1961.,  758., 1271.],\n",
      "        [ 118., 2437.,  397.,  648.],\n",
      "        [ 173., 3803.,  363.,  269.],\n",
      "        [  56., 1784.,  105., 1687.]])\n",
      "test Loss: 3.0595 Acc: 0.2911\n",
      "Epoch 27/74\n",
      "----------\n",
      "train Loss: 0.2695 Acc: 0.9210\n",
      "tensor([[ 164., 1913.,  781., 1302.],\n",
      "        [ 110., 2411.,  423.,  656.],\n",
      "        [ 176., 3792.,  366.,  274.],\n",
      "        [  56., 1779.,  105., 1692.]])\n",
      "test Loss: 3.0200 Acc: 0.2896\n",
      "Epoch 28/74\n",
      "----------\n",
      "train Loss: 0.2650 Acc: 0.9226\n",
      "tensor([[ 153., 1882.,  809., 1316.],\n",
      "        [  98., 2392.,  445.,  665.],\n",
      "        [ 171., 3779.,  368.,  290.],\n",
      "        [  56., 1772.,  103., 1701.]])\n",
      "test Loss: 2.9831 Acc: 0.2884\n",
      "Epoch 29/74\n",
      "----------\n",
      "train Loss: 0.2607 Acc: 0.9239\n",
      "tensor([[ 144., 1860.,  825., 1331.],\n",
      "        [  85., 2374.,  469.,  672.],\n",
      "        [ 169., 3772.,  370.,  297.],\n",
      "        [  56., 1769.,  103., 1704.]])\n",
      "test Loss: 2.9488 Acc: 0.2870\n",
      "Epoch 30/74\n",
      "----------\n",
      "train Loss: 0.2566 Acc: 0.9252\n",
      "tensor([[ 142., 1834.,  836., 1348.],\n",
      "        [  77., 2355.,  491.,  677.],\n",
      "        [ 164., 3765.,  371.,  308.],\n",
      "        [  55., 1767.,  106., 1704.]])\n",
      "test Loss: 2.9163 Acc: 0.2858\n",
      "Epoch 31/74\n",
      "----------\n",
      "train Loss: 0.2527 Acc: 0.9262\n",
      "tensor([[ 142., 1801.,  848., 1369.],\n",
      "        [  63., 2342.,  518.,  677.],\n",
      "        [ 162., 3757.,  372.,  317.],\n",
      "        [  55., 1767.,  110., 1700.]])\n",
      "test Loss: 2.8861 Acc: 0.2848\n",
      "Epoch 32/74\n",
      "----------\n",
      "train Loss: 0.2489 Acc: 0.9273\n",
      "tensor([[ 134., 1767.,  870., 1389.],\n",
      "        [  58., 2313.,  536.,  693.],\n",
      "        [ 156., 3748.,  371.,  333.],\n",
      "        [  55., 1761.,  114., 1702.]])\n",
      "test Loss: 2.8586 Acc: 0.2825\n",
      "Epoch 33/74\n",
      "----------\n",
      "train Loss: 0.2452 Acc: 0.9283\n",
      "tensor([[ 124., 1741.,  890., 1405.],\n",
      "        [  53., 2299.,  550.,  698.],\n",
      "        [ 151., 3744.,  371.,  342.],\n",
      "        [  54., 1748.,  118., 1712.]])\n",
      "test Loss: 2.8332 Acc: 0.2816\n",
      "Epoch 34/74\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2416 Acc: 0.9292\n",
      "tensor([[ 116., 1726.,  905., 1413.],\n",
      "        [  48., 2290.,  565.,  697.],\n",
      "        [ 146., 3733.,  375.,  354.],\n",
      "        [  54., 1739.,  118., 1721.]])\n",
      "test Loss: 2.8096 Acc: 0.2814\n",
      "Epoch 35/74\n",
      "----------\n",
      "train Loss: 0.2381 Acc: 0.9302\n",
      "tensor([[ 115., 1709.,  918., 1418.],\n",
      "        [  47., 2276.,  575.,  702.],\n",
      "        [ 142., 3725.,  375.,  366.],\n",
      "        [  53., 1733.,  117., 1729.]])\n",
      "test Loss: 2.7877 Acc: 0.2809\n",
      "Epoch 36/74\n",
      "----------\n",
      "train Loss: 0.2348 Acc: 0.9310\n",
      "tensor([[ 116., 1693.,  937., 1414.],\n",
      "        [  39., 2266.,  586.,  709.],\n",
      "        [ 139., 3712.,  376.,  381.],\n",
      "        [  52., 1721.,  117., 1742.]])\n",
      "test Loss: 2.7677 Acc: 0.2812\n",
      "Epoch 37/74\n",
      "----------\n",
      "train Loss: 0.2315 Acc: 0.9321\n",
      "tensor([[ 116., 1678.,  948., 1418.],\n",
      "        [  36., 2261.,  594.,  709.],\n",
      "        [ 137., 3709.,  378.,  384.],\n",
      "        [  51., 1710.,  121., 1750.]])\n",
      "test Loss: 2.7491 Acc: 0.2816\n",
      "Epoch 38/74\n",
      "----------\n",
      "train Loss: 0.2284 Acc: 0.9331\n",
      "tensor([[ 116., 1663.,  962., 1419.],\n",
      "        [  34., 2255.,  599.,  712.],\n",
      "        [ 133., 3702.,  380.,  393.],\n",
      "        [  49., 1705.,  121., 1757.]])\n",
      "test Loss: 2.7319 Acc: 0.2818\n",
      "Epoch 39/74\n",
      "----------\n",
      "train Loss: 0.2254 Acc: 0.9338\n",
      "tensor([[ 111., 1653.,  975., 1421.],\n",
      "        [  33., 2246.,  604.,  717.],\n",
      "        [ 125., 3700.,  381.,  402.],\n",
      "        [  49., 1697.,  122., 1764.]])\n",
      "test Loss: 2.7160 Acc: 0.2814\n",
      "Epoch 40/74\n",
      "----------\n",
      "train Loss: 0.2224 Acc: 0.9346\n",
      "tensor([[ 109., 1641.,  982., 1428.],\n",
      "        [  27., 2235.,  617.,  721.],\n",
      "        [ 122., 3689.,  385.,  412.],\n",
      "        [  46., 1693.,  128., 1765.]])\n",
      "test Loss: 2.7014 Acc: 0.2809\n",
      "Epoch 41/74\n",
      "----------\n",
      "train Loss: 0.2195 Acc: 0.9352\n",
      "tensor([[ 108., 1636.,  986., 1430.],\n",
      "        [  27., 2226.,  619.,  728.],\n",
      "        [ 120., 3683.,  388.,  417.],\n",
      "        [  46., 1691.,  132., 1763.]])\n",
      "test Loss: 2.6880 Acc: 0.2803\n",
      "Epoch 42/74\n",
      "----------\n",
      "train Loss: 0.2168 Acc: 0.9360\n",
      "tensor([[ 103., 1626.,  999., 1432.],\n",
      "        [  22., 2214.,  626.,  738.],\n",
      "        [ 117., 3666.,  394.,  431.],\n",
      "        [  45., 1684.,  130., 1773.]])\n",
      "test Loss: 2.6760 Acc: 0.2802\n",
      "Epoch 43/74\n",
      "----------\n",
      "train Loss: 0.2141 Acc: 0.9364\n",
      "tensor([[ 102., 1622., 1005., 1431.],\n",
      "        [  19., 2205.,  633.,  743.],\n",
      "        [ 111., 3658.,  404.,  435.],\n",
      "        [  43., 1682.,  135., 1772.]])\n",
      "test Loss: 2.6651 Acc: 0.2802\n",
      "Epoch 44/74\n",
      "----------\n",
      "train Loss: 0.2115 Acc: 0.9375\n",
      "tensor([[ 102., 1613., 1014., 1431.],\n",
      "        [  17., 2203.,  637.,  743.],\n",
      "        [ 109., 3644.,  415.,  440.],\n",
      "        [  42., 1680.,  138., 1772.]])\n",
      "test Loss: 2.6552 Acc: 0.2807\n",
      "Epoch 45/74\n",
      "----------\n",
      "train Loss: 0.2089 Acc: 0.9383\n",
      "tensor([[ 103., 1607., 1015., 1435.],\n",
      "        [  16., 2199.,  637.,  748.],\n",
      "        [ 103., 3632.,  426.,  447.],\n",
      "        [  42., 1680.,  139., 1771.]])\n",
      "test Loss: 2.6461 Acc: 0.2812\n",
      "Epoch 46/74\n",
      "----------\n",
      "train Loss: 0.2065 Acc: 0.9391\n",
      "tensor([[ 100., 1604., 1020., 1436.],\n",
      "        [  14., 2196.,  642.,  748.],\n",
      "        [  97., 3621.,  437.,  453.],\n",
      "        [  40., 1680.,  143., 1769.]])\n",
      "test Loss: 2.6377 Acc: 0.2814\n",
      "Epoch 47/74\n",
      "----------\n",
      "train Loss: 0.2041 Acc: 0.9399\n",
      "tensor([[ 102., 1598., 1021., 1439.],\n",
      "        [  12., 2193.,  647.,  748.],\n",
      "        [  96., 3602.,  447.,  463.],\n",
      "        [  35., 1683.,  146., 1768.]])\n",
      "test Loss: 2.6300 Acc: 0.2819\n",
      "Epoch 48/74\n",
      "----------\n",
      "train Loss: 0.2018 Acc: 0.9405\n",
      "tensor([[ 102., 1594., 1025., 1439.],\n",
      "        [  12., 2190.,  647.,  751.],\n",
      "        [  94., 3583.,  458.,  473.],\n",
      "        [  33., 1684.,  151., 1764.]])\n",
      "test Loss: 2.6235 Acc: 0.2821\n",
      "Epoch 49/74\n",
      "----------\n",
      "train Loss: 0.1995 Acc: 0.9410\n",
      "tensor([[ 102., 1586., 1031., 1441.],\n",
      "        [  10., 2182.,  650.,  758.],\n",
      "        [  90., 3569.,  468.,  481.],\n",
      "        [  30., 1685.,  147., 1770.]])\n",
      "test Loss: 2.6174 Acc: 0.2826\n",
      "Epoch 50/74\n",
      "----------\n",
      "train Loss: 0.1973 Acc: 0.9416\n",
      "tensor([[ 103., 1584., 1033., 1440.],\n",
      "        [  10., 2180.,  651.,  759.],\n",
      "        [  89., 3557.,  478.,  484.],\n",
      "        [  30., 1685.,  150., 1767.]])\n",
      "test Loss: 2.6121 Acc: 0.2830\n",
      "Epoch 51/74\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9419\n",
      "tensor([[ 101., 1583., 1035., 1441.],\n",
      "        [  10., 2171.,  656.,  763.],\n",
      "        [  88., 3545.,  491.,  484.],\n",
      "        [  25., 1686.,  153., 1768.]])\n",
      "test Loss: 2.6074 Acc: 0.2832\n",
      "Epoch 52/74\n",
      "----------\n",
      "train Loss: 0.1931 Acc: 0.9427\n",
      "tensor([[ 101., 1578., 1041., 1440.],\n",
      "        [  10., 2169.,  656.,  765.],\n",
      "        [  84., 3539.,  497.,  488.],\n",
      "        [  25., 1686.,  157., 1764.]])\n",
      "test Loss: 2.6029 Acc: 0.2832\n",
      "Epoch 53/74\n",
      "----------\n",
      "train Loss: 0.1911 Acc: 0.9432\n",
      "tensor([[ 100., 1576., 1045., 1439.],\n",
      "        [  10., 2162.,  657.,  771.],\n",
      "        [  85., 3534.,  498.,  491.],\n",
      "        [  20., 1686.,  164., 1762.]])\n",
      "test Loss: 2.5990 Acc: 0.2826\n",
      "Epoch 54/74\n",
      "----------\n",
      "train Loss: 0.1892 Acc: 0.9438\n",
      "tensor([[ 100., 1572., 1048., 1440.],\n",
      "        [  10., 2156.,  657.,  777.],\n",
      "        [  85., 3528.,  502.,  493.],\n",
      "        [  20., 1686.,  165., 1761.]])\n",
      "test Loss: 2.5954 Acc: 0.2824\n",
      "Epoch 55/74\n",
      "----------\n",
      "train Loss: 0.1873 Acc: 0.9442\n",
      "tensor([[ 103., 1570., 1050., 1437.],\n",
      "        [  10., 2144.,  660.,  786.],\n",
      "        [  82., 3519.,  508.,  499.],\n",
      "        [  18., 1689.,  170., 1755.]])\n",
      "test Loss: 2.5921 Acc: 0.2819\n",
      "Epoch 56/74\n",
      "----------\n",
      "train Loss: 0.1854 Acc: 0.9445\n",
      "tensor([[ 102., 1569., 1055., 1434.],\n",
      "        [  10., 2140.,  661.,  789.],\n",
      "        [  81., 3514.,  511.,  502.],\n",
      "        [  17., 1691.,  169., 1755.]])\n",
      "test Loss: 2.5894 Acc: 0.2818\n",
      "Epoch 57/74\n",
      "----------\n",
      "train Loss: 0.1836 Acc: 0.9449\n",
      "tensor([[ 101., 1567., 1060., 1432.],\n",
      "        [   9., 2132.,  665.,  794.],\n",
      "        [  81., 3500.,  522.,  505.],\n",
      "        [  15., 1690.,  170., 1757.]])\n",
      "test Loss: 2.5871 Acc: 0.2820\n",
      "Epoch 58/74\n",
      "----------\n",
      "train Loss: 0.1819 Acc: 0.9454\n",
      "tensor([[ 103., 1565., 1060., 1432.],\n",
      "        [   9., 2129.,  665.,  797.],\n",
      "        [  79., 3489.,  529.,  511.],\n",
      "        [  14., 1689.,  174., 1755.]])\n",
      "test Loss: 2.5852 Acc: 0.2823\n",
      "Epoch 59/74\n",
      "----------\n",
      "train Loss: 0.1802 Acc: 0.9458\n",
      "tensor([[ 102., 1563., 1062., 1433.],\n",
      "        [   6., 2125.,  669.,  800.],\n",
      "        [  76., 3482.,  535.,  515.],\n",
      "        [  14., 1684.,  178., 1756.]])\n",
      "test Loss: 2.5836 Acc: 0.2824\n",
      "Epoch 60/74\n",
      "----------\n",
      "train Loss: 0.1785 Acc: 0.9462\n",
      "tensor([[ 105., 1559., 1059., 1437.],\n",
      "        [   6., 2117.,  670.,  807.],\n",
      "        [  75., 3477.,  541.,  515.],\n",
      "        [  12., 1678.,  185., 1757.]])\n",
      "test Loss: 2.5820 Acc: 0.2825\n",
      "Epoch 61/74\n",
      "----------\n",
      "train Loss: 0.1769 Acc: 0.9465\n",
      "tensor([[ 105., 1557., 1063., 1435.],\n",
      "        [   6., 2112.,  675.,  807.],\n",
      "        [  74., 3469.,  546.,  519.],\n",
      "        [   9., 1674.,  187., 1762.]])\n",
      "test Loss: 2.5807 Acc: 0.2828\n",
      "Epoch 62/74\n",
      "----------\n",
      "train Loss: 0.1753 Acc: 0.9468\n",
      "tensor([[ 105., 1555., 1068., 1432.],\n",
      "        [   6., 2110.,  676.,  808.],\n",
      "        [  73., 3463.,  553.,  519.],\n",
      "        [   8., 1670.,  190., 1764.]])\n",
      "test Loss: 2.5796 Acc: 0.2833\n",
      "Epoch 63/74\n",
      "----------\n",
      "train Loss: 0.1738 Acc: 0.9471\n",
      "tensor([[ 103., 1553., 1074., 1430.],\n",
      "        [   6., 2105.,  678.,  811.],\n",
      "        [  73., 3454.,  560.,  521.],\n",
      "        [   8., 1665.,  197., 1762.]])\n",
      "test Loss: 2.5785 Acc: 0.2831\n",
      "Epoch 64/74\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9473\n",
      "tensor([[ 104., 1553., 1073., 1430.],\n",
      "        [   6., 2099.,  677.,  818.],\n",
      "        [  72., 3443.,  572.,  521.],\n",
      "        [   7., 1657.,  207., 1761.]])\n",
      "test Loss: 2.5778 Acc: 0.2835\n",
      "Epoch 65/74\n",
      "----------\n",
      "train Loss: 0.1708 Acc: 0.9476\n",
      "tensor([[ 103., 1553., 1076., 1428.],\n",
      "        [   6., 2088.,  677.,  829.],\n",
      "        [  70., 3436.,  577.,  525.],\n",
      "        [   5., 1649.,  211., 1767.]])\n",
      "test Loss: 2.5772 Acc: 0.2834\n",
      "Epoch 66/74\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9479\n",
      "tensor([[1.0600e+02, 1.5520e+03, 1.0800e+03, 1.4220e+03],\n",
      "        [6.0000e+00, 2.0850e+03, 6.7800e+02, 8.3100e+02],\n",
      "        [6.9000e+01, 3.4280e+03, 5.8200e+02, 5.2900e+02],\n",
      "        [3.0000e+00, 1.6490e+03, 2.0700e+02, 1.7730e+03]])\n",
      "test Loss: 2.5769 Acc: 0.2841\n",
      "Epoch 67/74\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9483\n",
      "tensor([[1.0600e+02, 1.5510e+03, 1.0830e+03, 1.4200e+03],\n",
      "        [6.0000e+00, 2.0710e+03, 6.7800e+02, 8.4500e+02],\n",
      "        [6.9000e+01, 3.4200e+03, 5.8900e+02, 5.3000e+02],\n",
      "        [3.0000e+00, 1.6460e+03, 2.1300e+02, 1.7700e+03]])\n",
      "test Loss: 2.5767 Acc: 0.2835\n",
      "Epoch 68/74\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1667 Acc: 0.9487\n",
      "tensor([[1.0600e+02, 1.5510e+03, 1.0820e+03, 1.4210e+03],\n",
      "        [6.0000e+00, 2.0680e+03, 6.7900e+02, 8.4700e+02],\n",
      "        [6.7000e+01, 3.4090e+03, 6.0100e+02, 5.3100e+02],\n",
      "        [3.0000e+00, 1.6440e+03, 2.1700e+02, 1.7680e+03]])\n",
      "test Loss: 2.5766 Acc: 0.2839\n",
      "Epoch 69/74\n",
      "----------\n",
      "train Loss: 0.1653 Acc: 0.9490\n",
      "tensor([[1.0700e+02, 1.5510e+03, 1.0890e+03, 1.4130e+03],\n",
      "        [6.0000e+00, 2.0600e+03, 6.8000e+02, 8.5400e+02],\n",
      "        [6.6000e+01, 3.3900e+03, 6.1600e+02, 5.3600e+02],\n",
      "        [2.0000e+00, 1.6420e+03, 2.2100e+02, 1.7670e+03]])\n",
      "test Loss: 2.5762 Acc: 0.2844\n",
      "Epoch 70/74\n",
      "----------\n",
      "train Loss: 0.1640 Acc: 0.9493\n",
      "tensor([[1.0800e+02, 1.5500e+03, 1.0880e+03, 1.4140e+03],\n",
      "        [6.0000e+00, 2.0580e+03, 6.8000e+02, 8.5600e+02],\n",
      "        [6.6000e+01, 3.3790e+03, 6.2500e+02, 5.3800e+02],\n",
      "        [1.0000e+00, 1.6310e+03, 2.3400e+02, 1.7660e+03]])\n",
      "test Loss: 2.5758 Acc: 0.2848\n",
      "Epoch 71/74\n",
      "----------\n",
      "train Loss: 0.1627 Acc: 0.9496\n",
      "tensor([[1.1100e+02, 1.5470e+03, 1.0890e+03, 1.4130e+03],\n",
      "        [5.0000e+00, 2.0580e+03, 6.8100e+02, 8.5600e+02],\n",
      "        [6.6000e+01, 3.3610e+03, 6.4200e+02, 5.3900e+02],\n",
      "        [1.0000e+00, 1.6290e+03, 2.3700e+02, 1.7650e+03]])\n",
      "test Loss: 2.5759 Acc: 0.2860\n",
      "Epoch 72/74\n",
      "----------\n",
      "train Loss: 0.1615 Acc: 0.9497\n",
      "tensor([[1.1100e+02, 1.5470e+03, 1.0910e+03, 1.4110e+03],\n",
      "        [5.0000e+00, 2.0560e+03, 6.8200e+02, 8.5700e+02],\n",
      "        [6.5000e+01, 3.3500e+03, 6.5400e+02, 5.3900e+02],\n",
      "        [1.0000e+00, 1.6200e+03, 2.4800e+02, 1.7630e+03]])\n",
      "test Loss: 2.5764 Acc: 0.2865\n",
      "Epoch 73/74\n",
      "----------\n",
      "train Loss: 0.1603 Acc: 0.9500\n",
      "tensor([[1.1000e+02, 1.5440e+03, 1.0980e+03, 1.4080e+03],\n",
      "        [4.0000e+00, 2.0500e+03, 6.8400e+02, 8.6200e+02],\n",
      "        [6.2000e+01, 3.3330e+03, 6.7300e+02, 5.4000e+02],\n",
      "        [1.0000e+00, 1.6160e+03, 2.5700e+02, 1.7580e+03]])\n",
      "test Loss: 2.5768 Acc: 0.2869\n",
      "Epoch 74/74\n",
      "----------\n",
      "train Loss: 0.1591 Acc: 0.9503\n",
      "tensor([[1.1000e+02, 1.5410e+03, 1.1040e+03, 1.4050e+03],\n",
      "        [4.0000e+00, 2.0480e+03, 6.8400e+02, 8.6400e+02],\n",
      "        [6.1000e+01, 3.3170e+03, 6.9200e+02, 5.3800e+02],\n",
      "        [1.0000e+00, 1.6130e+03, 2.6600e+02, 1.7520e+03]])\n",
      "test Loss: 2.5773 Acc: 0.2876\n",
      "Training complete in 96m 2s\n",
      "Best test Acc: 0.305375\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (75,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5c821f9378dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy and Loss for testing and testing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/enter/envs/Keira_pytorch_env/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/enter/envs/Keira_pytorch_env/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/enter/envs/Keira_pytorch_env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/enter/envs/Keira_pytorch_env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/enter/envs/Keira_pytorch_env/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (75,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters\n",
    "lr_max = 1*10e-1\n",
    "\n",
    "factor = 6\n",
    "end_lr = lr_max\n",
    "iter=0\n",
    "total_logs = []\n",
    "features_layers = 91\n",
    "step_size = 4*len(dataloaders[\"train\"])\n",
    "Epo = [x for x in range(50)]\n",
    "\n",
    "# Do 3 sequential runs\n",
    "for run in tqdm(range(3)):\n",
    "    # Instantiate the model \n",
    "    modelRes50 = model.resnet50_128(weights_path='./model/resnet50_128.pth')\n",
    "   # modelRes50.add_module(\"feat_extract1\",nn.Conv2d(128, 64, kernel_size=[1, 1], stride=(1, 1), bias=False))\n",
    "   # modelRes50.add_module(\"feat_extract2\",nn.Conv2d(64, 4, kernel_size=[1, 1], stride=(1, 1), bias=False))\n",
    "    #modelRes50.add_layers([modelRes50.feat_extract1, modelRes50.feat_extract2])\n",
    "    modelRes50.add_module(\"Add_pool\",nn.AvgPool2d(kernel_size=[14, 14], stride=[1, 1], padding=0))\n",
    "    modelRes50.add_module(\"feat_extract0\",nn.Conv2d(1024, 4, kernel_size=[1, 1], stride=(1, 1), bias=False))\n",
    "    modelRes50.add_layers([modelRes50.Add_pool, modelRes50.feat_extract0])\n",
    "    \n",
    "    modelRes50, para_list = freezing(modelRes50, features_layers)\n",
    "    modelRes50 = modelRes50.to(device)\n",
    "    \n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Define the optimizer \n",
    "    \n",
    "    optimizer_ft = optim.SGD(para_list, lr=1.)    \n",
    "    clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
    "    exp_lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_ft, [clr])\n",
    "    modelRes50, Acc, Los = epoch_mode(modelRes50, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=75) \n",
    "    \n",
    "    plt.title('Accuracy and Loss for testing and testing')\n",
    "    plt.subplot(2, 1, 1)   \n",
    "    plt.plot(Epo, Acc[\"train\"], 'g--')\n",
    "    plt.plot(Epo, Acc[\"test\"], 'r--')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend('Training accuracy', 'Testing accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(Epo, Los[\"train\"], 'y--')\n",
    "    plt.plot(Epo, Los[\"test\"], 'b--')    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend('Training loss', 'Testing loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# modelRes50, Acc, Los = epoch_mode(modelRes50, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epo = [x for x in range(5)]\n",
    "    \n",
    "# plt.title('Accuracy and Loss for testing and testing')\n",
    "# plt.subplot(2, 1, 1)   \n",
    "# plt.plot(Epo, Acc[\"train\"], 'g^')\n",
    "# plt.plot(Epo, Acc[\"test\"], 'r--')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend('Training accuracy', 'Testing accuracy')\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(Epo, Los[\"train\"], 'y*')\n",
    "# plt.plot(Epo, Los[\"test\"], 'bs')    \n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend('Training loss', 'Testing loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nb_classes = 4\n",
    "\n",
    "# confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "# with torch.no_grad():\n",
    "#     for i, (inputs, classes) in enumerate(dataloaders['test']):\n",
    "#         inputs = inputs.to(device)\n",
    "#         classes = classes.to(device)\n",
    "#         outputs = modelRes50(inputs)\n",
    "#         _, preds = torch.max(outputs, 1)\n",
    "#         for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "#                 confusion_matrix[t.long(), p.long()] += 1\n",
    "# print(class_names)\n",
    "# print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
